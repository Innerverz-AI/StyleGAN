# model 
model_id: StyleGAN

# multi-GPUs
use_mGPU: True

# validation
use_validation: True

# wandb
use_wandb: True
wandb_alert_thres: 1000

# root
train_dataset_root_list: [
                # "/media/deep3090/새 볼륨/celeba_hq",
                # '/home/compu/dataset/CelebHQ',
                '/home/compu/dataset/ffhq16k'
            ]
valid_dataset_root: 
save_root: train_result

# ---------- #
# Rosinality #
# ---------- #
path: /home/leee/data/ffhq70k/   # path of specified dataset

code_size: 512
# batch_size: 16
n_critic: 1

gen_sample: 
  512: [8, 4]
  1024: [4, 2]


phase: 600_000      # number of samples used for each training phases

# batch size
batch_default: 8
batch: 
  4: 512
  8: 256
  16: 128
  32: 64  
  64: 32
  128: 16 # 32
  256: 16 # 32

# learning rate
lr_default: 0.001
lr:
  128: 0.0015
  256: 0.002
  512: 0.003
  1024: 0.003
# sched: True         # use lr scheduling

# image size
init_size: 8        # initial image size
max_size: 1024      # max image isze

# checkpoint
# ckpt: None          # load from previous checkpoints

# etc.
no_from_rgb_activate: False     # use activate in from_rgb (original implementation)
mixing: False        # use mixing regularization
loss: r1       # class of gan loss, choices = [wgan-gp, r1]


# --------- #
# Innerverz #
# --------- #
# learning rate
# lr_G: 0.0001
# lr_D: 0.00001
# beta1: 0
# beta2: 0.999

# weight of loss
W_adv: 1
W_gp: 10

# hyperparameters
same_prob: 0.2
# batch_per_gpu: 4
max_step: 400000

# log cycle
loss_cycle: 10
test_cycle: 1000
ckpt_cycle: 10000

# ckpt path
# blank is None, but None is "None"
load_ckpt: False
ckpt_id:
ckpt_step:
# ckpt_id: run0424
# ckpt_step: 30000

## Pretrained models paths
arcface_path: ptnn/arcface.pth
